You've done a fantastic job completing the SLAM project üëè

You might want to check out the resources below for some inspiration and to further improve your model and solidify your understanding of the material:

SLAM wiki cause we always miss reading the basics & history
https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping
SLAM algorithms paper
https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/Durrant-Whyte_Bailey_SLAM-tutorial-I.pdf
SLAM for dummies by MIT
https://dspace.mit.edu/bitstream/handle/1721.1/36832/16-412JSpring2004/NR/rdonlyres/Aeronautics-and-Astronautics/16-412JSpring2004/A3C5517F-C092-4554-AA43-232DC74609B3/0/1Aslam_blas_report.pdf

Keep up the great work üëçüèΩ

Congratulations once again üéâ Happy Learning and have a great time with your further endeavours üòä

Leave a rating if the review was helpful üòá

`robot_class.py`: Implementation of `sense`
Implement the sense function to complete the robot class found in the robot_class.py file. This implementation should account for a given amount of measurement_noise and the measurement_range of the robot. This function should return a list of values that reflect the measured distance (dx, dy) between the robot's position and any landmarks it sees. One item in the returned list has the format: [landmark_index, dx, dy].

The sense function is very well written! Good job keeping the measurement_range only to 50,
You have perfectly added the measurement_noise to both dx and dy parameters,
The function is also returning the right values.

Notebook 3: Implementation of `initialize_constraints`
Initialize the array omega and vector xi such that any unknown values are 0 the size of these should vary with the given world_size, num_landmarks, and time step, N, parameters.

The constraints are correctly initialized and your way of keeping the X and Y as well as omega values is new and creative, that shows you have invested proper time in the project which is good to see and appreciated.

Notebook 3: Implementation of `slam`
The values in the constraint matrices should be affected by sensor measurements and these updates should account for uncertainty in sensing.

You have perfectly taken into account of motion_noise and measurement_noise to account for any sensory information if they are connected, like in the real world scenarios.

The values in the constraint matrices should be affected by motion (dx, dy) and these updates should account for uncertainty in motion.

The values of constraint matrices are affected by the motion and it shows the robot is moving as per the motion measurements. It's the right implementation.

The values in mu will be the x, y positions of the robot over time and the estimated locations of landmarks in the world. mu is calculated with the constraint matrices omega^(-1)*xi.

mu is calculated correctly. The values of mu and estimated locations are making sense which is satisfactory!

Compare the slam-estimated and true final pose of the robot; answer why these values might be different.

The slam estimate and true final post of the robot are a little far away which makes sense as the N is very small here.

There are two provided test_data cases, test your implementation of slam on them and see if the result matches.

The difference in the results is due to floating point or matrix inverse calculations. Getting your test results right means your code is working well and its always nice to validate your implementation, its a very good coding practice!
